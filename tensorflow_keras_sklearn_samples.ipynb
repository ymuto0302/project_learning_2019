{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "[1] 0.16920000314712524\n",
      "[11] 0.65829998254776\n",
      "[21] 0.730400025844574\n",
      "[31] 0.761900007724762\n",
      "[41] 0.7968000173568726\n",
      "[51] 0.8402000069618225\n",
      "[61] 0.8048999905586243\n",
      "[71] 0.8615999817848206\n",
      "[81] 0.8105999827384949\n",
      "[91] 0.8790000081062317\n",
      "[101] 0.8859000205993652\n",
      "[111] 0.8497999906539917\n",
      "[121] 0.863099992275238\n",
      "[131] 0.9035999774932861\n",
      "[141] 0.8840000033378601\n",
      "[151] 0.8830000162124634\n",
      "[161] 0.8946999907493591\n",
      "[171] 0.8932999968528748\n",
      "[181] 0.8860999941825867\n",
      "[191] 0.8956000208854675\n",
      "[201] 0.8920000195503235\n",
      "[211] 0.8984000086784363\n",
      "[221] 0.8970999717712402\n",
      "[231] 0.9097999930381775\n",
      "[241] 0.8971999883651733\n",
      "[251] 0.9070000052452087\n",
      "[261] 0.9172000288963318\n",
      "[271] 0.9161999821662903\n",
      "[281] 0.9128000140190125\n",
      "[291] 0.9180999994277954\n",
      "[301] 0.920799970626831\n",
      "[311] 0.9133999943733215\n",
      "[321] 0.9203000068664551\n",
      "[331] 0.9243000149726868\n",
      "[341] 0.9215999841690063\n",
      "[351] 0.9185000061988831\n",
      "[361] 0.9266999959945679\n",
      "[371] 0.9186000227928162\n",
      "[381] 0.9197999835014343\n",
      "[391] 0.9261000156402588\n",
      "[401] 0.930899977684021\n",
      "[411] 0.9301000237464905\n",
      "[421] 0.9258000254631042\n",
      "[431] 0.9286999702453613\n",
      "[441] 0.9251000285148621\n",
      "[451] 0.9211999773979187\n",
      "[461] 0.9311000108718872\n",
      "[471] 0.9301000237464905\n",
      "[481] 0.9193999767303467\n",
      "[491] 0.9291999936103821\n",
      "[501] 0.9217000007629395\n",
      "[511] 0.9337999820709229\n",
      "[521] 0.9368000030517578\n",
      "[531] 0.9283999800682068\n",
      "[541] 0.9314000010490417\n",
      "[551] 0.9282000064849854\n",
      "[561] 0.9347000122070312\n",
      "[571] 0.9297999739646912\n",
      "[581] 0.9308000206947327\n",
      "[591] 0.9312000274658203\n",
      "[601] 0.9402999877929688\n",
      "[611] 0.9326000213623047\n",
      "[621] 0.9312999844551086\n",
      "[631] 0.9423999786376953\n",
      "[641] 0.9290000200271606\n",
      "[651] 0.9275000095367432\n",
      "[661] 0.9325000047683716\n",
      "[671] 0.9373000264167786\n",
      "[681] 0.9259999990463257\n",
      "[691] 0.9431999921798706\n",
      "[701] 0.9358999729156494\n",
      "[711] 0.9409000277519226\n",
      "[721] 0.9390000104904175\n",
      "[731] 0.9369999766349792\n",
      "[741] 0.9372000098228455\n",
      "[751] 0.9387000203132629\n",
      "[761] 0.9388999938964844\n",
      "[771] 0.9391999840736389\n",
      "[781] 0.9298999905586243\n",
      "[791] 0.9343000054359436\n",
      "[801] 0.9429000020027161\n",
      "[811] 0.9401999711990356\n",
      "[821] 0.9386000037193298\n",
      "[831] 0.9352999925613403\n",
      "[841] 0.9415000081062317\n",
      "[851] 0.9333999752998352\n",
      "[861] 0.9391999840736389\n",
      "[871] 0.9390000104904175\n",
      "[881] 0.941100001335144\n",
      "[891] 0.930899977684021\n",
      "[901] 0.9365000128746033\n",
      "[911] 0.9384999871253967\n",
      "[921] 0.9455000162124634\n",
      "[931] 0.9358000159263611\n",
      "[941] 0.9453999996185303\n",
      "[951] 0.9380999803543091\n",
      "[961] 0.9430999755859375\n",
      "[971] 0.9437000155448914\n",
      "[981] 0.9437000155448914\n",
      "[991] 0.9354000091552734\n",
      "[1001] 0.9362000226974487\n",
      "[1011] 0.9415000081062317\n",
      "[1021] 0.9343000054359436\n",
      "[1031] 0.9405999779701233\n",
      "[1041] 0.9368000030517578\n",
      "[1051] 0.9416999816894531\n",
      "[1061] 0.9473000168800354\n",
      "[1071] 0.9426000118255615\n",
      "[1081] 0.9441999793052673\n",
      "[1091] 0.9434999823570251\n",
      "[1101] 0.9474999904632568\n",
      "[1111] 0.9435999989509583\n",
      "[1121] 0.9476000070571899\n",
      "[1131] 0.9437000155448914\n",
      "[1141] 0.9447000026702881\n",
      "[1151] 0.9401999711990356\n",
      "[1161] 0.9491000175476074\n",
      "[1171] 0.9474999904632568\n",
      "[1181] 0.942799985408783\n",
      "[1191] 0.9444000124931335\n",
      "[1201] 0.9434999823570251\n",
      "[1211] 0.9444000124931335\n",
      "[1221] 0.9442999958992004\n",
      "[1231] 0.9492999911308289\n",
      "[1241] 0.9438999891281128\n",
      "[1251] 0.9488999843597412\n",
      "[1261] 0.9420999884605408\n",
      "[1271] 0.9366000294685364\n",
      "[1281] 0.9501000046730042\n",
      "[1291] 0.9394999742507935\n",
      "[1301] 0.9491000175476074\n",
      "[1311] 0.9480000138282776\n",
      "[1321] 0.944100022315979\n",
      "[1331] 0.9412000179290771\n",
      "[1341] 0.9416999816894531\n",
      "[1351] 0.9453999996185303\n",
      "[1361] 0.947700023651123\n",
      "[1371] 0.9503999948501587\n",
      "[1381] 0.9456999897956848\n",
      "[1391] 0.9519000053405762\n",
      "[1401] 0.9498999714851379\n",
      "[1411] 0.9480999708175659\n",
      "[1421] 0.9470000267028809\n",
      "[1431] 0.9430999755859375\n",
      "[1441] 0.9422000050544739\n",
      "[1451] 0.947700023651123\n",
      "[1461] 0.9484999775886536\n",
      "[1471] 0.9490000009536743\n",
      "[1481] 0.9404000043869019\n",
      "[1491] 0.9456999897956848\n",
      "[1501] 0.9488000273704529\n",
      "[1511] 0.9466000199317932\n",
      "[1521] 0.9456999897956848\n",
      "[1531] 0.946399986743927\n",
      "[1541] 0.9523000121116638\n",
      "[1551] 0.9516000151634216\n",
      "[1561] 0.9462000131607056\n",
      "[1571] 0.9469000101089478\n",
      "[1581] 0.9513000249862671\n",
      "[1591] 0.9480999708175659\n",
      "[1601] 0.9528999924659729\n",
      "[1611] 0.9491000175476074\n",
      "[1621] 0.9491000175476074\n",
      "[1631] 0.9437000155448914\n",
      "[1641] 0.9514999985694885\n",
      "[1651] 0.9488999843597412\n",
      "[1661] 0.9470000267028809\n",
      "[1671] 0.95169997215271\n",
      "[1681] 0.9527999758720398\n",
      "[1691] 0.9516000151634216\n",
      "[1701] 0.9449999928474426\n",
      "[1711] 0.9521999955177307\n",
      "[1721] 0.9501000046730042\n",
      "[1731] 0.949999988079071\n",
      "[1741] 0.9545999765396118\n",
      "[1751] 0.9503999948501587\n",
      "[1761] 0.9509999752044678\n",
      "[1771] 0.9488999843597412\n",
      "[1781] 0.9505000114440918\n",
      "[1791] 0.9509000182151794\n",
      "[1801] 0.9501000046730042\n",
      "[1811] 0.9502999782562256\n",
      "[1821] 0.9502999782562256\n",
      "[1831] 0.9541000127792358\n",
      "[1841] 0.9492999911308289\n",
      "[1851] 0.9513000249862671\n",
      "[1861] 0.9528999924659729\n",
      "[1871] 0.9549999833106995\n",
      "[1881] 0.9513000249862671\n",
      "[1891] 0.9544000029563904\n",
      "[1901] 0.9514999985694885\n",
      "[1911] 0.9559000134468079\n",
      "[1921] 0.9516000151634216\n",
      "[1931] 0.9537000060081482\n",
      "[1941] 0.9508000016212463\n",
      "[1951] 0.9495999813079834\n",
      "[1961] 0.9502999782562256\n",
      "[1971] 0.9538999795913696\n",
      "[1981] 0.9484000205993652\n",
      "[1991] 0.9460999965667725\n",
      "[2001] 0.9542999863624573\n",
      "[2011] 0.9513000249862671\n",
      "[2021] 0.9490000009536743\n",
      "[2031] 0.9473000168800354\n",
      "[2041] 0.9520999789237976\n",
      "[2051] 0.95169997215271\n",
      "[2061] 0.9488000273704529\n",
      "[2071] 0.95169997215271\n",
      "[2081] 0.9490000009536743\n",
      "[2091] 0.9546999931335449\n",
      "[2101] 0.9496999979019165\n",
      "[2111] 0.9539999961853027\n",
      "[2121] 0.9478999972343445\n",
      "[2131] 0.9501000046730042\n",
      "[2141] 0.9519000053405762\n",
      "[2151] 0.9502999782562256\n",
      "[2161] 0.9524999856948853\n",
      "[2171] 0.949999988079071\n",
      "[2181] 0.9516000151634216\n",
      "[2191] 0.953499972820282\n",
      "[2201] 0.9541000127792358\n",
      "[2211] 0.9569000005722046\n",
      "[2221] 0.9532999992370605\n",
      "[2231] 0.9545000195503235\n",
      "[2241] 0.9544000029563904\n",
      "[2251] 0.9523000121116638\n",
      "[2261] 0.9502000212669373\n",
      "[2271] 0.951200008392334\n",
      "[2281] 0.95169997215271\n",
      "[2291] 0.9510999917984009\n",
      "[2301] 0.954800009727478\n",
      "[2311] 0.9539999961853027\n",
      "[2321] 0.9534000158309937\n",
      "[2331] 0.9578999876976013\n",
      "[2341] 0.9473000168800354\n",
      "[2351] 0.9452000260353088\n",
      "[2361] 0.9460999965667725\n",
      "[2371] 0.9480000138282776\n",
      "[2381] 0.9532999992370605\n",
      "[2391] 0.9552000164985657\n",
      "[2401] 0.9510999917984009\n",
      "[2411] 0.9574000239372253\n",
      "[2421] 0.9549999833106995\n",
      "[2431] 0.953000009059906\n",
      "[2441] 0.9524999856948853\n",
      "[2451] 0.9495999813079834\n",
      "[2461] 0.9524999856948853\n",
      "[2471] 0.9581999778747559\n",
      "[2481] 0.95169997215271\n",
      "[2491] 0.9534000158309937\n",
      "[2501] 0.9521999955177307\n",
      "[2511] 0.9559999704360962\n",
      "[2521] 0.9585000276565552\n",
      "[2531] 0.9563999772071838\n",
      "[2541] 0.9546999931335449\n",
      "[2551] 0.9514999985694885\n",
      "[2561] 0.9502999782562256\n",
      "[2571] 0.9517999887466431\n",
      "[2581] 0.9557999968528748\n",
      "[2591] 0.9480000138282776\n",
      "[2601] 0.9588000178337097\n",
      "[2611] 0.9535999894142151\n",
      "[2621] 0.9564999938011169\n",
      "[2631] 0.9534000158309937\n",
      "[2641] 0.9501000046730042\n",
      "[2651] 0.9556000232696533\n",
      "[2661] 0.9567999839782715\n",
      "[2671] 0.9521999955177307\n",
      "[2681] 0.9553999900817871\n",
      "[2691] 0.9527999758720398\n",
      "0.9498\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DNN (tensorflow)による MNIST 分類\n",
    "(メモ) dropout によって性能は上がる (91% → 94%) が，同時に early stopping 機構を組み込む必要あり。\n",
    "(メモ) tensorflow は early stopping 機構はあるのかしら？ Keras には実装されているようだが。\n",
    "'''\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "# sess = tf.InteractiveSession()\n",
    "sess = tf.Session()\n",
    "\n",
    "# モデルの作成\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "'''\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "'''\n",
    "\n",
    "'''\n",
    "W = weight_variable([784, 10])\n",
    "b = bias_variable([10])\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "'''\n",
    "\n",
    "enable_dropout = tf.placeholder_with_default(False, [], name=\"enable_dropout\")\n",
    "h1_keep_prob = tf.constant(0.5, dtype=tf.float32)\n",
    "\n",
    "W1 = weight_variable([784, 362])\n",
    "b1 = bias_variable([362])\n",
    "h1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "h1_drop = tf.nn.dropout(h1, h1_keep_prob)\n",
    "\n",
    "W2 = weight_variable([362, 10])\n",
    "b2 = bias_variable([10])\n",
    "y = tf.nn.softmax(tf.matmul(h1_drop, W2) + b2)\n",
    "\n",
    "# 損失とオプティマイザーを定義\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    " \n",
    "# 訓練\n",
    "tf.initialize_all_variables().run()\n",
    "for i in range(2700): # 元の値は 1000 である\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    train_step.run({x: batch_xs, y_: batch_ys, enable_dropout: True})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        print(\"[{}] {}\".format(i+1, accuracy.eval({x: mnist.test.images, y_: mnist.test.labels, enable_dropout: False})))\n",
    "\n",
    "# 訓練モデルのテスト\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9818571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       678\n",
      "           1       0.99      0.99      0.99       806\n",
      "           2       0.98      0.99      0.98       686\n",
      "           3       0.98      0.99      0.98       737\n",
      "           4       0.99      0.98      0.98       671\n",
      "           5       0.98      0.96      0.97       634\n",
      "           6       0.98      0.99      0.99       671\n",
      "           7       0.98      0.98      0.98       730\n",
      "           8       0.99      0.97      0.98       691\n",
      "           9       0.96      0.98      0.97       696\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      7000\n",
      "   macro avg       0.98      0.98      0.98      7000\n",
      "weighted avg       0.98      0.98      0.98      7000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npredictions = []\\nfor i in range(X_test.shape[0]):\\n    o = mlp.predict(X_test[i])\\n    predictions.append(np.argmax(o))\\nprint(confusion_matrix(y_test, predictions))\\nprint(classification_report(y_test, predictions))\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "MLP(scikit-learn)による MNIST 分類\n",
    "'''\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# mnistの手書き数字データをロード\n",
    "# カレントディレクトリ（.）にない場合は、\n",
    "# Webから自動的にダウンロードされる（時間がかかるので注意！）\n",
    "# 70000サンプル、28x28ピクセル\n",
    "X, y = sklearn.datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# ピクセルの値を0.0-1.0に正規化\n",
    "X = X.astype(np.float64)\n",
    "X /= X.max()\n",
    "\n",
    "# 訓練データとテストデータに分解\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# 教師信号の数字を1-of-K表記に変換\n",
    "#labels_train = LabelBinarizer().fit_transform(y_train)\n",
    "#labels_test = LabelBinarizer().fit_transform(y_test)\n",
    "\n",
    "# 多層パーセプトロンを構築\n",
    "# mlp = MLPClassifier(max_iter=1000, early_stopping=True)\n",
    "mlp = MLPClassifier((362, 181), max_iter=1000, early_stopping=True)\n",
    "\n",
    "# 訓練データを用いてニューラルネットの重みを学習\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# テストデータを用いて予測精度を計算\n",
    "print(mlp.score(X_test, y_test))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "'''\n",
    "predictions = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    o = mlp.predict(X_test[i])\n",
    "    predictions.append(np.argmax(o))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2478 - acc: 0.9240 - val_loss: 0.1210 - val_acc: 0.9635\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.1047 - acc: 0.9686 - val_loss: 0.0779 - val_acc: 0.9749\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0742 - acc: 0.9774 - val_loss: 0.0944 - val_acc: 0.9724\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0593 - acc: 0.9820 - val_loss: 0.0730 - val_acc: 0.9803\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0507 - acc: 0.9852 - val_loss: 0.0794 - val_acc: 0.9795\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0441 - acc: 0.9867 - val_loss: 0.0693 - val_acc: 0.9823\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0367 - acc: 0.9891 - val_loss: 0.0752 - val_acc: 0.9824\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0364 - acc: 0.9892 - val_loss: 0.0744 - val_acc: 0.9832\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0309 - acc: 0.9908 - val_loss: 0.0870 - val_acc: 0.9823\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0289 - acc: 0.9918 - val_loss: 0.0896 - val_acc: 0.9836\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0280 - acc: 0.9919 - val_loss: 0.0995 - val_acc: 0.9823\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0247 - acc: 0.9930 - val_loss: 0.0988 - val_acc: 0.9824\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0260 - acc: 0.9930 - val_loss: 0.0852 - val_acc: 0.9831\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0234 - acc: 0.9933 - val_loss: 0.1150 - val_acc: 0.9824\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0215 - acc: 0.9939 - val_loss: 0.1333 - val_acc: 0.9821\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0202 - acc: 0.9945 - val_loss: 0.1100 - val_acc: 0.9834\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0191 - acc: 0.9947 - val_loss: 0.1124 - val_acc: 0.9832\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0179 - acc: 0.9948 - val_loss: 0.1127 - val_acc: 0.9840\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0183 - acc: 0.9951 - val_loss: 0.1393 - val_acc: 0.9828\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0177 - acc: 0.9955 - val_loss: 0.1218 - val_acc: 0.9833\n",
      "Test loss: 0.1218474535544138\n",
      "Test accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Kerasによる MNIST 分類\n",
    "'''\n",
    "import tensorflow.contrib.keras\n",
    "from tensorflow.contrib.keras.api.keras.datasets import mnist\n",
    "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense, Dropout\n",
    "from tensorflow.contrib.keras.api.keras.optimizers import RMSprop\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
